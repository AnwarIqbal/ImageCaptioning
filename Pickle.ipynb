{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 80\n"
     ]
    }
   ],
   "source": [
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "    doc = load_doc(filename)\n",
    "    dataset = list()\n",
    "    # process line by line\n",
    "    for line in doc.split('\\n'):\n",
    "        # skip empty lines\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        # get the image identifier\n",
    "        identifier = line.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return set(dataset)\n",
    "\n",
    "# load training dataset (6K)\n",
    "train_images_file = '/Users/anwariqbal/Desktop/data/text/Train.txt'\n",
    "train = load_set(train_images_file)\n",
    "print('Dataset: %d' % len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below path contains all the images\n",
    "images = '/Users/anwariqbal/Desktop/data/images/'\n",
    "# Create a list of all image names in the directory\n",
    "img = glob.glob(images + '*.jpg')\n",
    "\n",
    "# Below file conatains the names of images to be used in train data\n",
    "#train_images_file = '../../storage/image_caption/dataset/TextFiles/Flickr_8k.trainImages.txt'\n",
    "# Read the train image names in a set\n",
    "train_images = set(open(train_images_file, 'r').read().strip().split('\\n'))\n",
    "\n",
    "# Create a list of all the training images with their full path names\n",
    "train_img = []\n",
    "\n",
    "for i in img: # img is list of full path names of all images\n",
    "    if i[len(images):] in train_images: # Check if the image belongs to training set\n",
    "        train_img.append(i) # Add it to the list of train images\n",
    "\n",
    "# Below file conatains the names of images to be used in test data\n",
    "test_images_file = '/Users/anwariqbal/Desktop/data/text/Test.txt'\n",
    "# Read the validation image names in a set# Read the test image names in a set\n",
    "test_images = set(open(test_images_file, 'r').read().strip().split('\\n'))\n",
    "\n",
    "# Create a list of all the test images with their full path names\n",
    "test_img = []\n",
    "\n",
    "for i in img: # img is list of full path names of all images\n",
    "    if i[len(images):] in test_images: # Check if the image belongs to test set\n",
    "        test_img.append(i) # Add it to the list of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "    # load document\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = dict()\n",
    "    for line in doc.split('\\n'):\n",
    "    # split line by white space\n",
    "        tokens = line.split()\n",
    "        # split id from description\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # skip images not in the set\n",
    "        if image_id in dataset:\n",
    "            # create list\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = list()\n",
    "            # wrap description in tokens\n",
    "            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "            # store\n",
    "            descriptions[image_id].append(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: train=80\n"
     ]
    }
   ],
   "source": [
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('/Users/anwariqbal/Desktop/data/text/Desc.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
    "    img = image.load_img(image_path, target_size=(299, 299))\n",
    "    # Convert PIL image to numpy array of 3-dimensions\n",
    "    x = image.img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # preprocess the images using preprocess_input() from inception module\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the inception v3 model\n",
    "model = InceptionV3(weights='imagenet')\n",
    "# Create a new model, by removing the last layer (output layer) from the inception v3\n",
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a given image into a vector of size (2048, )\n",
    "def encode(image):\n",
    "    image = preprocess(image) # preprocess the image\n",
    "    fea_vec = model_new.predict(image) # Get the encoding vector for the image\n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "    return fea_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds = 34.92657780647278\n"
     ]
    }
   ],
   "source": [
    "# Call the funtion to encode all the train images\n",
    "# This will take a while on CPU - Execute this only once\n",
    "start = time()\n",
    "encoding_train = {}\n",
    "for img in train_img:\n",
    "    encoding_train[img[len(images):]] = encode(img)\n",
    "print(\"Time taken in seconds =\", time()-start)\n",
    "\n",
    "with open(\"/Users/anwariqbal/Desktop/data/encoded_train_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    dump(encoding_train, encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds = 6.363566875457764\n"
     ]
    }
   ],
   "source": [
    "# Call the funtion to encode all the test images - Execute this only once\n",
    "start = time()\n",
    "encoding_test = {}\n",
    "for img in test_img:\n",
    "    encoding_test[img[len(images):]] = encode(img)\n",
    "print(\"Time taken in seconds =\", time()-start)\n",
    "\n",
    "# Save the bottleneck test features to disk\n",
    "with open(\"/Users/anwariqbal/Desktop/data/encoded_test_images.pkl\", \"wb\") as encoded_pickle:\n",
    "    dump(encoding_test, encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
